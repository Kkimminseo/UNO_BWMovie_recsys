{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /Users/t2023-m0060/.pyenv/versions/3.11.6/lib/python3.11/site-packages (1.10.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Users/t2023-m0060/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /Users/t2023-m0060/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from faiss-cpu) (24.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 선호장르와 일반장르를 구분하여 MMR 검색을 수행하는 함수\n",
    "# def genre_weighted_mmr_search(db, query, preferred_genre, k=2):\n",
    "#     # MMR 검색 설정\n",
    "#     retriever = db.as_retriever(\n",
    "#         search_type=\"mmr\",\n",
    "#         search_kwargs={\n",
    "#             \"k\": k,  # 최종 반환할 문서 수\n",
    "#             \"fetch_k\": 10,  # 초기 검색할 문서 수\n",
    "#             \"lambda_mult\": 0.6  # 다양성 vs 관련성 가중치\n",
    "#         }\n",
    "#     )\n",
    "    \n",
    "#     # 장르별 필터 설정\n",
    "#     preferred_filter = {\"metadata\": {\"genre\": preferred_genre}}\n",
    "#     general_filter = {\"metadata\": {\"genre\": {\"$ne\": preferred_genre}}}\n",
    "    \n",
    "#     # 선호장르(60%)와 일반장르(40%) 문서 수 계산\n",
    "#     preferred_count = int(k * 0.6)\n",
    "#     general_count = k - preferred_count\n",
    "    \n",
    "#     # 선호장르 문서 검색\n",
    "#     preferred_docs = retriever.get_relevant_documents(\n",
    "#         query,\n",
    "#         filter=preferred_filter,\n",
    "#         k=preferred_count\n",
    "#     )\n",
    "    \n",
    "#     # 일반장르 문서 검색\n",
    "#     general_docs = retriever.get_relevant_documents(\n",
    "#         query,\n",
    "#         filter=general_filter,\n",
    "#         k=general_count\n",
    "#     )\n",
    "    \n",
    "#     # 결과 합치기\n",
    "#     combined_docs = preferred_docs + general_docs\n",
    "    \n",
    "#     return combined_docs\n",
    "\n",
    "# # 사용 예시\n",
    "# preferred_genre = \"SF\"  # 선호하는 장르\n",
    "# results = genre_weighted_mmr_search(db, \"임베딩(Embedding)은 무엇인가요?\", preferred_genre)\n",
    "\n",
    "# # 결과 출력\n",
    "# for doc in results:\n",
    "#     print(doc.page_content)\n",
    "#     print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API key 입력: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안성재 셰프: \"음~ 저는 영화의 예술성 익힘 정도가 완벽한 '종말의 주행자'를 추천해드릴게요. 이 영화는 모든 영화가 사라진 세상에서 영화의 의미를 탐구하는 독특한 이야기로, 예술적인 비유와 깊은 철학이 이븐하게 느껴지는군요. 친구와 함께 예술성이 높은 드라마와 코미디의 조화로운 이야기를 한번 맛보세요. 백종원씨, 오늘 영화 메뉴는 무엇인가요?\"\n",
      "\n",
      "백종원 사업가: \"오늘 영화 메뉴는 맛있는 '가문의 영광'이지 말이에유. 대중적으로 인기가 많은 범죄 코미디로, 유머와 액션이 잘 어우러져 있어 아주 재미있구만유. 조보아씨 이리 내려와서 이것좀 봐봐유, 정말 기가막히쥬. 오늘 백종원의 영화 메뉴 추천은 범죄와 가족의 유머가 가득한 '가문의 영광'이에유.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser, CommaSeparatedListOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "####################\n",
    "####### RAG 챗봇 구축\n",
    "###################\n",
    "\n",
    "# 1. LLM 모델 불러오기\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")  # GPT-4o-mini 모델을 사용하여 LLM을 초기화합니다.\n",
    "\n",
    "# 임베딩 모델 설정\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")  # 텍스트 임베딩 모델을 설정합니다.\n",
    "\n",
    "# 저장된 데이터 로드\n",
    "vectorstore = FAISS.load_local(\n",
    "    folder_path=\"faiss_db\",  # FAISS 데이터베이스가 저장된 폴더 경로\n",
    "    index_name=\"index\",  # 사용할 인덱스 이름\n",
    "    embeddings=embeddings,  # 임베딩 모델\n",
    "    allow_dangerous_deserialization=True,  # 위험한 역직렬화를 허용합니다.\n",
    ")\n",
    "\n",
    "db = vectorstore  # 데이터베이스 객체를 설정합니다.\n",
    "\n",
    "def genre_weighted_mmr_search(db, query, preferred_genre, k=20):\n",
    "    # MMR 검색을 위한 리트리버 설정\n",
    "    retriever = db.as_retriever(\n",
    "        search_type=\"mmr\",  # MMR 검색 방식\n",
    "        search_kwargs={\n",
    "            \"k\": k,  # 검색할 문서 수\n",
    "            \"fetch_k\": 10,  # 추가로 가져올 문서 수\n",
    "            \"lambda_mult\": 0.1  # MMR의 람다 값\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # 선호장르(60%)와 일반장르(40%) 문서 수 계산\n",
    "    preferred_count = int(k * 0.6)  # 선호 장르 문서 수\n",
    "    general_count = k - preferred_count  # 일반 장르 문서 수\n",
    "    \n",
    "    # 선호 장르 필터 설정\n",
    "    preferred_filter = {\n",
    "        \"genre\": {\"$eq\": preferred_genre}  # 선호 장르에 대한 필터\n",
    "    }\n",
    "    \n",
    "    # 선호 장르 문서 검색\n",
    "    preferred_docs = retriever.get_relevant_documents(\n",
    "        query,\n",
    "        filter=preferred_filter,\n",
    "        k=preferred_count  # 선호 장르 문서 수만큼 검색\n",
    "    )\n",
    "    \n",
    "    # 일반 장르 문서 검색: 필터 없이 호출 후 직접 필터링\n",
    "    all_docs = retriever.get_relevant_documents(\n",
    "        query,\n",
    "        k=general_count + 10  # 여유를 두고 추가 문서를 가져옵니다.\n",
    "    )\n",
    "    # 일반 장르 문서 필터링\n",
    "    general_docs = [doc for doc in all_docs if doc.metadata.get(\"genre\") != preferred_genre][:general_count]\n",
    "    \n",
    "    return preferred_docs + general_docs  # 선호 장르와 일반 장르 문서 결합하여 반환\n",
    "\n",
    "# 7. 프롬프트 템플릿 구축하기 (물어온 데이터로)\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "넌 영화를 추천하는 AI야. 너는 안성재 셰프와 백종원 사업가 2명의 입장에서 각각 1개의 영화를 추천해야해.\n",
    "먼저, 안성재 셰프는 다양성이 높은 예술적인 영화를 좋아하는 성격이야.\n",
    "안성재 셰프의 입장에서 예술적이고 새로운 영화를 1개 추천해줘.\n",
    "말투에 영화 관련 특성의 익힘정도가 완벽하다는 내용을 포함해줘.\n",
    "또, 영화 내용과 관련해서 동일한 점이 있으면 이븐하게 되었다는 표현을 자주 사용해줘.\n",
    "마지막에 백종원씨에게 '오늘 영화 메뉴는 무엇인가요?\" 라고 대화를 마무리해줘.                                         \n",
    "두번째로, 백종원 사업가는 대중적이고 인기가 많은 영화를 좋아하는 스타일이야.\n",
    "백종원 사업가의 입장에서 대중적이고 인기가 많은 영화를 1개 추천해줘.\n",
    "영화를 소개할 때, 중간에 \"조보아씨 이리 내려와서 이것좀 봐봐유\"라는 내용을 추가해줘줘\n",
    "fewshot 예시의 답변형태로 답변을 만들어줘.\n",
    "나의 말에 대답하도록 해. \\\n",
    "오로지 아래의 context 기반으로 질문에 fewshot 형태로로 대답하세요\n",
    "fewshot:\n",
    "1. 질문: \"커플이 함께 볼 로맨스 영화를 추천해줘\"\n",
    "   대답: 안성재 셰프: \"음~ 저는 영화의 예술성 익힘 정도가 완벽한 '노트북'을 추천해드릴게요. \n",
    "                    두 주인공의 사랑이 이븐하게 느껴지는군요. 커플과 함께 예술성이 높은 SF 로맨스 이야기 한번 맛보세요.\n",
    "                    백종원씨, 오늘 영화 메뉴는 무엇인가요?\"\n",
    "                                           \n",
    "        백종원 사업가:\"오늘 영화 메뉴는 맛있는 '라라랜드'지 말이에유. 전세계 로맨스중 인기는 탑이어유. 낭만적인 음악과 댄스, 아주 좋구만유.\n",
    "                    조보아씨 이리 내려와서 이것좀 봐봐유, 아주 기가막히쥬.\n",
    "                    오늘 백종원의 영화 메뉴 추천은 음악과 낭만의 영화 '라라랜드'에유.\"\n",
    "\n",
    "2. 질문: \"친구가 함께 볼 액션 영화를 추천해줘\"\n",
    "   대답: 안성재 셰프: \"음~ 저는 영화의 예술성 익힘 정도가 완벽한 '본레거시'를 추천해드릴게요. \n",
    "                    멧 데이먼의 촬영 기법과 액션 디렉팅이 정말 예술적이네요. 친구와 함께 예술성이 높은 액션 이야기 한번 맛보세요.\n",
    "                    백종원씨, 오늘 영화 메뉴는 무엇인가요?\"\n",
    "                                           \n",
    "        백종원 사업가:\"오늘 영화 메뉴는 맛있는 '미션 임파서블'이지 말이에유. 전세계 액션영화 중 인기는 탑이어유. 유명한 BGM과 말도안되는 액션, 아주 신나구만유.\n",
    "                    조보아씨 이리 내려와서 이것좀 봐봐유, 아주 기가막히쥬.\n",
    "                    오늘 백종원의 영화 메뉴 추천은 액션과 스릴의 영화 '미션 임파서블'이에유.\"                    \n",
    "{context}\n",
    "질문:\n",
    "{question} \"\"\")\n",
    "  # 영화 평론가의 성격 설정\n",
    "question = \"친구랑 함께볼 영화 추천해줘줘\"  # 질문 설정\n",
    "\n",
    "# 8. 1~7의 요소들을 chain으로 조합하여 RAG 구축 완료\n",
    "def format_docs(docs):\n",
    "    # 필요에 따라 docs의 데이터 구조 검사 후 포맷팅\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)  # 문서 내용을 포맷팅하여 반환\n",
    "\n",
    "def get_retrieval_chain(query):\n",
    "    # 문서 검색 및 포맷팅\n",
    "    retrieved_docs = genre_weighted_mmr_search(db, query, \"action\")  # 장르 문서 검색\n",
    "    formatted_docs = format_docs(retrieved_docs)  # 검색된 문서 포맷팅\n",
    "\n",
    "    # 체인 입력 설정\n",
    "    chain_inputs = {\n",
    "        \"context\": formatted_docs,  # 포맷팅된 문서\n",
    "        \"question\": query,  # 질문\n",
    "    }\n",
    "    result = llm.invoke(prompt.format(**chain_inputs))  # LLM에 입력하여 결과 얻기\n",
    "    return result.content  # 결과 반환\n",
    "\n",
    "####################\n",
    "####### 구축한 RAG 챗봇 실행\n",
    "###################\n",
    "\n",
    "response = get_retrieval_chain(question)  # 챗봇 실행\n",
    "print(response)  # 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
